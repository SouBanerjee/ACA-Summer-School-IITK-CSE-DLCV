{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c17d6c",
   "metadata": {},
   "source": [
    "\n",
    "# Tensors\n",
    "\n",
    "Tensors are similar to NumPyâ€™s ndarrays, except that tensors can run on GPUs or other specialized hardware to accelerate computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af8c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789af8c2",
   "metadata": {},
   "source": [
    "## Tensor Initialization\n",
    "\n",
    "Tensors can be initialized in various ways. Take a look at the following examples:\n",
    "\n",
    "**Directly from data**\n",
    "\n",
    "Tensors can be created directly from data. The data type is automatically inferred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e5ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b38fe",
   "metadata": {},
   "source": [
    "**From a NumPy array**\n",
    "\n",
    "Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9f4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ad0e6",
   "metadata": {},
   "source": [
    "**From another tensor:**\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e7c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.8896, 0.7317],\n",
      "        [0.8255, 0.2639]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(\"Ones Tensor: \\n {} \\n\".format(x_ones))\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(\"Random Tensor: \\n {} \\n\".format(x_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6e33b",
   "metadata": {},
   "source": [
    "**With random or constant values:**\n",
    "\n",
    "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617be00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0687, 0.5021, 0.6481],\n",
      "        [0.1861, 0.7458, 0.4851]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(\"Random Tensor: \\n {} \\n\".format(rand_tensor))\n",
    "print(\"Ones Tensor: \\n {} \\n\".format(ones_tensor))\n",
    "print(\"Zeros Tensor: \\n {}\".format(zeros_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad3eaf",
   "metadata": {},
   "source": [
    "## Tensor Attributes\n",
    "\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35fb63aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(\"Shape of tensor: {}\".format(tensor.shape))\n",
    "print(\"Datatype of tensor: {}\".format(tensor.dtype))\n",
    "print(\"Device tensor is stored on: {}\".format(tensor.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b711b2",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f818ec",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6581ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(\"Device tensor is stored on: {}\".format(tensor.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b82341",
   "metadata": {},
   "source": [
    "**Standard numpy-like indexing and slicing:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4aff928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(tensor, '\\n\\n')\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d524b15",
   "metadata": {},
   "source": [
    "#### Joining tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2f091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ba8c4",
   "metadata": {},
   "source": [
    "**Multiplying tensors**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4241c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product\n",
    "print(\"tensor.mul(tensor) \\n {} \\n\".format(tensor.mul(tensor)))\n",
    "# Alternative syntax:\n",
    "print(\"tensor * tensor \\n {}\".format(tensor * tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584debe",
   "metadata": {},
   "source": [
    "#### matrix multiplication between two tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a223ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"tensor.matmul(tensor.T) \\n {} \\n\".format(tensor.matmul(tensor.T)))\n",
    "# Alternative syntax:\n",
    "print(\"tensor @ tensor.T \\n {}\".format(tensor @ tensor.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb620a4",
   "metadata": {},
   "source": [
    "#### In-place operations\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b68819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb7bf4",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe3af4",
   "metadata": {},
   "source": [
    "\n",
    "## Bridge with NumPy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
    "locations, and changing one will change\tthe other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df80c67",
   "metadata": {},
   "source": [
    "### Tensor to NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aacf33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(\"t: {}\".format(t))\n",
    "n = t.numpy()\n",
    "print(\"n: {}\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbfaa0",
   "metadata": {},
   "source": [
    "A change in the tensor reflects in the NumPy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b990c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(\"t: {}\".format(t))\n",
    "print(\"n: {}\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da6a5a",
   "metadata": {},
   "source": [
    "### NumPy array to Tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78dc8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68946ff",
   "metadata": {},
   "source": [
    "Changes in the NumPy array reflects in the tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82c199eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(\"t: {}\".format(t))\n",
    "print(\"n: {}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85f980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48678449",
   "metadata": {},
   "source": [
    "## Differentiation in Autograd\n",
    "Let's take a look at how ``autograd`` collects gradients. We create two tensors ``a`` and ``b`` with\n",
    "``requires_grad=True``. This signals to ``autograd`` that every operation on them should be tracked.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d44469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c3058",
   "metadata": {},
   "source": [
    "We create another tensor ``Q`` from ``a`` and ``b``.\n",
    "\n",
    "\\begin{align}Q = 3a^3 - b^2\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9841ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9296fd",
   "metadata": {},
   "source": [
    "Let's assume ``a`` and ``b`` to be parameters of an NN, and ``Q``\n",
    "to be the error. In NN training, we want gradients of the error\n",
    "w.r.t. parameters, i.e.\n",
    "\n",
    "\\begin{align}\\frac{\\partial Q}{\\partial a} = 9a^2\\end{align}\n",
    "\n",
    "\\begin{align}\\frac{\\partial Q}{\\partial b} = -2b\\end{align}\n",
    "\n",
    "\n",
    "When we call ``.backward()`` on ``Q``, autograd calculates these gradients\n",
    "and stores them in the respective tensors' ``.grad`` attribute.\n",
    "\n",
    "We need to explicitly pass a ``gradient`` argument in ``Q.backward()`` because it is a vector.\n",
    "``gradient`` is a tensor of the same shape as ``Q``, and it represents the\n",
    "gradient of Q w.r.t. itself, i.e.\n",
    "\n",
    "\\begin{align}\\frac{dQ}{dQ} = 1\\end{align}\n",
    "\n",
    "Equivalently, we can also aggregate Q into a scalar and call backward implicitly, like ``Q.sum().backward()``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80ed987",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ed77d",
   "metadata": {},
   "source": [
    "Gradients are now deposited in ``a.grad`` and ``b.grad``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87addc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "# check if collected gradients are correct\n",
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389144d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd2b9a4",
   "metadata": {},
   "source": [
    "### Computational Graph & Exclusion from the DAG\n",
    "\n",
    "Conceptually, autograd keeps a record of data (tensors) & all executed operations (along with the resulting new tensors) in a directed acyclic graph (DAG).\n",
    "\n",
    "In a forward pass, autograd does two things simultaneously:\n",
    "\n",
    "- run the requested operation to compute a resulting tensor, and\n",
    "- maintain the operationâ€™s *gradient function* in the DAG.\n",
    "\n",
    "The backward pass kicks off when ``.backward()`` is called on the DAG\n",
    "root. ``autograd`` then:\n",
    "\n",
    "- computes the gradients from each ``.grad_fn``,\n",
    "- accumulates them in the respective tensorâ€™s ``.grad`` attribute, and\n",
    "- using the chain rule, propagates all the way to the leaf tensors.\n",
    "\n",
    "\n",
    "``torch.autograd`` tracks operations on all tensors which have their ``requires_grad`` flag set to ``True``. For tensors that donâ€™t require gradients, setting this attribute to ``False`` excludes it from the gradient computation DAG.\n",
    "\n",
    "The output tensor of an operation will require gradients even if only a single input tensor has ``requires_grad=True``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3f4366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n",
      "\n",
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n",
      "\n",
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((5, 5), requires_grad=True)\n",
    "y = torch.rand((5, 5), requires_grad=True)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    a = x + y\n",
    "print(\"Does `a` require gradients? : {}\".format(a.requires_grad))\n",
    "b = x + z\n",
    "print(\"Does `b` require gradients?: {}\\n\".format(b.requires_grad))\n",
    "\n",
    "x.requires_grad = False\n",
    "y.requires_grad = False\n",
    "\n",
    "a = x + y\n",
    "print(\"Does `a` require gradients? : {}\".format(a.requires_grad))\n",
    "b = x + z\n",
    "print(\"Does `b` require gradients?: {}\\n\".format(b.requires_grad))\n",
    "\n",
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(\"Does `a` require gradients? : {}\".format(a.requires_grad))\n",
    "b = x + z\n",
    "print(\"Does `b` require gradients?: {}\\n\".format(b.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06cb21b",
   "metadata": {},
   "source": [
    "**[Credits](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e709b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
